from __future__ import annotations
import os
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass

import orjson
from dotenv import load_dotenv
from docx import Document
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.output_parsers import JsonOutputParser



@dataclass
class OOPPrinciple:
    """
    Data class representing an object-oriented principle detected in the project.

    Attributes:
        present (bool): Whether the principle is present in the project
        description (str): Description of the principle
        code_snippets (List[str]): List of code snippets, each with
        keys "file" and "code".
    """
    present: bool
    description: str
    code_snippets: List[Dict[str, str]]


@dataclass
class ResumeItem:
    """
    Data class representing a project resume item generated by the AI analysis.
    
    Attributes:
        project_title (str): The title/name of the project
        one_sentence_summary (str): Brief one-line description of the project
        detailed_summary (str): Comprehensive description of the project
        key_responsibilities (List[str]): List of main tasks/roles in the project
        key_skills_used (List[str]): List of skills demonstrated in the project
        tech_stack (str): Main technologies and tools used in the project
        impact (str): The significance or results achieved by the project
    """
    project_title: str
    one_sentence_summary: str
    detailed_summary: str
    key_responsibilities: List[str]
    key_skills_used: List[str]
    tech_stack: str
    impact: str
    oop_principles_detected: Dict[str, OOPPrinciple]


class GenerateProjectResume:
    IMAGE_EXTS = {".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".webp"}

    TEXT_EXTS = {".txt", ".md", ".rst", ".log"}

    CODE_EXTS = {
        # Python
        ".py", ".pyw", ".ipynb",".pyscript",

        # Web & JavaScript/TypeScript
        ".js", ".jsx", ".mjs", ".cjs", ".ts", ".tsx",

        # Java & JVM Languages
        ".java", ".kt", ".kts", ".scala", ".groovy",

        # C/C++ Family
        ".c", ".h", ".cpp", ".hpp", ".cc", ".cxx",

        # .NET
        ".cs", ".vb",

        # Web & Markup
        ".html", ".htm",
        ".css", ".scss", ".sass", ".less",
        ".vue", ".svelte",
        ".xml", ".svg",

        # Scripting
        ".rb", ".pl", ".pm", ".t", ".py",
        ".lua", ".r", ".R", ".m", ".jl",
        ".sh", ".bash", ".zsh", ".ps1", ".psm1", ".bat", ".cmd",
        ".php",

        # Systems & Compiled
        ".go", ".rs", ".swift", ".dart",
        ".zig", ".nim",
        ".m", ".mm",  # Objective-C/Objective-C++
        ".d", ".pas",
        ".f", ".f90", ".f95",  # Fortran
        ".asm", ".s",  # Assembly
        ".cu", ".cuh",  # CUDA
        ".cl",  # OpenCL

        # Configuration & Data
        ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg",
        ".env", ".properties",
        ".sql", ".hql", ".cql",  # Database
        ".graphql", ".gql",
        ".tf", ".tfvars", ".hcl",  # Terraform

        # Build & Package Management
        ".gradle", ".pom.xml", ".csproj", ".fsproj", ".vbproj",
        ".cabal", ".hs-boot",
        ".cabal", ".hs-boot",
        ".nuspec",
        ".sln", ".vcxproj",
        ".bazel", ".bzl",
        ".buck",
        ".buckconfig",
        ".gn", ".gni"
    }



    def __init__(self,folder):

        """
        Initialize a GenerateProjectResume instance.

        :param folder: The root directory of the project
        :raises FileNotFoundError: If the given folder does not exist
        :raises RuntimeError: If the GOOGLE_API_KEY environment variable is not set
        """
        load_dotenv()
        self.google_model="gemini-2.5-flash" #Define what Gemini model we are going to be using
        self.folder=folder
        self.saveToJson=False
        self.returnResume=None
        self.max_chars: int = 20_000
        self.project_root=Path(self.folder) #Getting the root folder path
        if not self.project_root.exists():
            raise FileNotFoundError(f"No such folder {self.project_root}")

        self.google_api_key = os.getenv("GOOGLE_API_KEY") #Get the Google_API_key stored in the .env file

        # If it's not added in the .env file, its raises a runtime error
        if not self.google_api_key:
            raise RuntimeError("Missing GOOGLE_API_KEY in .env file")


        #Here we are creating an instance of the LLM (langchain_google_genai.ChatGoogleGenerativeAI)
        # and passing in the model and the Google_api_key to authenticate the LLM.
        self.llm = ChatGoogleGenerativeAI(
            model=self.google_model,
            google_api_key=self.google_api_key
        )

        # Here we are creating an instance of the parser to parse the output from the LLM into JSON format
        self.parser = JsonOutputParser()



        """
        Here we are creating the prompt template to be sent to the LLM
        which in this case in gemini-2.5-flash
        """
        self.langChain_prompt = PromptTemplate.from_template(
            """
            You are an expert technical résumé writer.

            You are given a snapshot of a software project including:
            - file structure
            - code snippets (any language including PHP)
            - documentation (PDF/DOCX/TXT)
            - configuration files

            Return a single JSON object summarizing the entire project:

            {{
              "project_title": "...",
              "one_sentence_summary": "...",
              "detailed_summary": "...",
              "key_responsibilities": [
                "bullet point...",
                "bullet point..."
              ],
              "key_skills_used": [
                "skill...",
                "technology..."
              ],
              "tech_stack": "short paragraph of main technologies" and ,
              "impact": "optional short impact statement",
              "oop_principles_detected": {{
                "abstraction": {{
                  "present": false,
                  "description": "",
                  "code_snippets": []
                }},
                "encapsulation": {{
                  "present": false,
                  "description": "",
                  "code_snippets": []
                }},
                "inheritance": {{
                  "present": false,
                  "description": "",
                  "code_snippets": []
                }},
                "polymorphism": {{
                  "present": false,
                  "description": "",
                  "code_snippets": []
                }}
              }}
            }}

            For "key_skills_used", include both technical tools (languages, frameworks, libraries, databases, etc.)
            and conceptual skills (e.g., testing strategies, design patterns, cloud, CI/CD).
            When the project demonstrates object-oriented design, explicitly include object-oriented principles
            such as abstraction, encapsulation, inheritance, and polymorphism as skills where appropriate.

            For "oop_principles_detected":
            - For each principle (abstraction, encapsulation, inheritance, polymorphism):
              - Set "present" to true or false (JSON booleans).
              - If present, fill "description" with a short explanation referencing the file/class/method.
              - If present, "code_snippets" MUST be a non-empty array of objects like:
                {{
                  "file": "relative/path/to/file.ext",
                  "code": "EXACT code excerpt that demonstrates the principle"
                }}.
              - The "code" field MUST contain a direct copy of the relevant code from the project context
                (class definitions, methods, interface implementations, overridden methods, etc.).
              - Do NOT wrap code in markdown fences (no ```), only plain text inside the JSON string.
            - If a principle is not detected, leave:
              - "present": false
              - "description": ""
              - "code_snippets": []

            Do NOT output anything except valid JSON.

            PROJECT CONTEXT:
            \"\"\"{project_context}\"\"\"
            """
        )

        self.chain=self.langChain_prompt | self.llm | self.parser


    def _is_text_file(self, path: Path) -> bool:
        try:
            with path.open("rb") as f:
                f.read(2048).decode("utf-8")
            return True
        except Exception:
            return False


    def _classify_file(self, path: Path) -> str:
        """

        Classify a file by its extension or contents.

        Returns one of the following strings:
        - "ignore": if the file is an image or cannot be read
        - "pdf": if the file is a PDF
        - "docx": if the file is a DOCX or DOC
        - "text": if the file is a plaintext file
        - "code": if the file is a source code file or contains code snippets

        :param path: The path to the file to classify
        :type path: Path
        :return: A string indicating the type of the file
        :rtype: str
        """

        #Here we are getting the file extension type
        file_extension=path.suffix.lower()

        if file_extension in self.IMAGE_EXTS:
            return "ignore"

        if file_extension == ".pdf":
            return "pdf"

        if file_extension == ".docx" or file_extension == '.doc':
            return "docx"

        if file_extension in self.TEXT_EXTS:
            return "text"

        if file_extension in self.CODE_EXTS:
            return "code"

        if self._is_text_file(path):
            return "code"


        return "ignore"


    def _read_file(self,path:Path)->str:
        """
        Reads the contents of a file.

        The type of the file is determined by calling `_classify_file`.

        If the file is a PDF, it is read using PyPDFLoader.
        If the file is a DOCX, it is read using Python-Docx.
        If the file is a plaintext file or contains code snippets, it is read using Path.read_text.

        Returns the contents of the file as a string.
        If an exception occurs during file reading, an empty string is returned.

        :param path: The path to the file to read
        :type path: Path
        :return: The contents of the file as a string
        :rtype: str
        """
        # Here we are using the classify_file function to determine the type of the file
        ftype=self._classify_file(path)
        try:
            if ftype=="pdf":
                pdf_to_read = PyPDFLoader(str(path)).load()
                pdf_content = "\n".join(p.page_content for p in pdf_to_read)
                content=pdf_content
            elif ftype=="docx":
                docx_to_read = Document(str(path))
                doc_content="\n".join(d.text for d in docx_to_read.paragraphs)
                content=doc_content
            elif ftype in {"text", "code"}:
                content=path.read_text(errors="ignore")

            else:
                return ""

            return content
        except Exception:
            return ""

    def _build_context(self):
        """
        Builds a string context from the project root and its files.

        The context string is formatted as follows:
        - ROOT: <project root path>\n
        - FILES:\n
        - <file path> [<file type>]\n
        - SNIPPETS:\n
        - === <file path> [<file type>] ===\n
        - <file snippet>\n
        - === <file path> [<file type>] ===\n
        - ...

        If the total length of the context string exceeds `max_chars`, the remaining snippets are truncated.

        :return: The context string
        :rtype: str
        """
        pieces: List[str] = [f"ROOT: {self.project_root.resolve()}\n", "FILES:\n"]
        total_length=0
        file_infos=[]

        for f in sorted(self.project_root.glob("**/*")):
            if f.is_file() and self._classify_file(f)!='ignore':
                ftype=self._classify_file(f)
                save_dict={"path":f,"type":ftype}
                file_infos.append(save_dict)
                pieces.append(f"- {f.relative_to(self.project_root)} [{ftype}]\n")
        pieces.append("\nSNIPPETS:\n")


        for info in file_infos:
            path=info.get("path")
            ftype=info.get("type")
            rel=path.relative_to(self.project_root)

            raw=self._read_file(path)
            if not raw.strip():
                continue
            snippet=raw.strip()[:1200]
            block = f"\n=== {rel} [{ftype}] ===\n{snippet}\n"
            if total_length+len(block)>self.max_chars:
                pieces.append("\n[TRUNCATED]\n")
                break

            pieces.append(block)
            total_length+=len(block)

        return "".join(pieces)

    def save_json_orjson(self, save_loc):
        if self.saveToJson:
            filePath = Path(save_loc)
            filePath.parent.mkdir(parents=True, exist_ok=True)
            json_bytes = orjson.dumps(self.returnResume,
                                      option=orjson.OPT_INDENT_2 | orjson.OPT_SORT_KEYS

                                      )
            filePath.write_bytes(json_bytes)



    def generate(self,saveToJson=False)->ResumeItem:
        """
        Generates a resume item for the given project root.

        The resume item is generated by running the AI chain on the project context.

        The project context is built by recursively traversing the project root and its files,
        and extracting snippets from the files. The snippets are then fed into the AI chain,
        which generates a resume item based on the snippets.

        :return: The generated resume item
        :rtype: ResumeItem
        """
        self.saveToJson=saveToJson
        print(f"running analysis on {self.project_root.name}")
        context=self._build_context()
        result=self.chain.invoke({"project_context":context}) #Here we are invoke the llm to start the analysis process
        raw_oop = result.get("oop_principles_detected", {}) or {}
        oop_principles: Dict[str, OOPPrinciple] = {}
        for name,data in raw_oop.items():
            if not isinstance(data, dict):
                continue
            oop_principles[name] = OOPPrinciple(
                present=bool(data.get("present", False)),
                description=data.get("description", "") or "",
                code_snippets=data.get("code_snippets", []) or [],

            )

        # Create ResumeItem from the LLM's JSON response with safe dictionary access
        self.returnResume = ResumeItem(
            # Project title from the analysis
            project_title=result.get("project_title", ""),
            # Brief project summary in one sentence
            one_sentence_summary=result.get("one_sentence_summary", ""),
            # Detailed project description
            detailed_summary=result.get("detailed_summary", ""),
            # List of main responsibilities/tasks
            key_responsibilities=result.get("key_responsibilities", []),
            # Technologies and skills demonstrated
            key_skills_used=result.get("key_skills_used", []),
            # Main technologies used in the project
            tech_stack=result.get("tech_stack", ""),
            # Project's impact or achievements
            impact=result.get("impact", ""),
            # Object-oriented principles detected in the project
            oop_principles_detected=oop_principles,

        )
        if saveToJson:
            save_path = f"output/{self.project_root.name}_resume.json"
            self.save_json_orjson(save_path)

        return self.returnResume



class GenerateLocalResume:
    """
    Generate a ResumeItem from local OOP analysis data without external AI.

    This class creates resume content using the metrics from the local analysis
    system 
    """

    def __init__(self, analysis_data: dict, project_name: str = "Project"):
        """
        Initialize with analysis data from the local OOP analyzer.

        Args:
            analysis_data: Dict containing resume_item, oop_analysis, etc.
            project_name: Name of the project.
        """
        self.analysis = analysis_data
        self.project_name = project_name

    def _build_resume_line(self, langs: List[str], frameworks: List[str],
                           skills: List[str], oop_analysis: dict, duration: str) -> str:
        """
        Build a comprehensive one-line resume sentence including all key factors.

        Args:
            langs: List of programming languages
            frameworks: List of frameworks used
            skills: List of skills demonstrated
            oop_analysis: OOP analysis metrics dict
            duration: Project duration estimate

        Returns:
            A single sentence summarizing the project for a resume.
        """
        parts = []

        # Start with project name and action verb
        parts.append(f"Developed {self.project_name}")

        # Add languages
        if langs:
            if len(langs) == 1:
                parts.append(f"using {langs[0]}")
            else:
                parts.append(f"using {', '.join(langs[:-1])} and {langs[-1]}")

        # Add frameworks
        if frameworks:
            if len(frameworks) == 1:
                parts.append(f"with {frameworks[0]} framework")
            else:
                parts.append(f"with {', '.join(frameworks)} frameworks")

        # Add OOP metrics if available
        classes_data = oop_analysis.get("classes", {})
        class_count = classes_data.get("count", 0)
        complexity = oop_analysis.get("complexity", {})
        func_count = complexity.get("total_functions", 0)

        if class_count > 0 and func_count > 0:
            parts.append(f"featuring {class_count} classes and {func_count} functions")
        elif class_count > 0:
            parts.append(f"featuring {class_count} classes")
        elif func_count > 0:
            parts.append(f"featuring {func_count} functions")

        # Add OOP principles if detected
        oop_features = []
        if classes_data.get("with_inheritance", 0) > 0:
            oop_features.append("inheritance")
        if oop_analysis.get("encapsulation", {}).get("classes_with_private_attrs", 0) > 0:
            oop_features.append("encapsulation")
        if oop_analysis.get("polymorphism", {}).get("classes_overriding_base_methods", 0) > 0:
            oop_features.append("polymorphism")

        if oop_features:
            parts.append(f"demonstrating {', '.join(oop_features)}")

        # Add key skills (limit to top 3)
        if skills:
            top_skills = skills[:3]
            if len(top_skills) == 1:
                parts.append(f"showcasing {top_skills[0]}")
            else:
                parts.append(f"showcasing {', '.join(top_skills[:-1])} and {top_skills[-1]}")

        # Add duration if available
        if duration and duration != "—":
            parts.append(f"over {duration}")

        # Join parts into a sentence
        sentence = " ".join(parts) + "."
        return sentence

    def generate(self, saveToJson: bool = False) -> ResumeItem:
        """
        Generate a ResumeItem from local analysis data.

        Args:
            saveToJson: Whether to save output to JSON (not implemented for local).

        Returns:
            ResumeItem populated with local analysis data.
        """
        resume_data = self.analysis.get("resume_item", {})
        oop_analysis = self.analysis.get("oop_analysis", {})

        # Extract basic info
        langs = resume_data.get("languages", [])
        frameworks = resume_data.get("frameworks", [])
        skills = resume_data.get("skills", [])
        summary = resume_data.get("summary", "")
        duration = self.analysis.get("duration_estimate", "")

        # Build tech stack string
        tech_parts = []
        if langs:
            tech_parts.append(", ".join(langs))
        if frameworks:
            tech_parts.append(", ".join(frameworks))
        tech_stack = "; ".join(tech_parts) if tech_parts else "Not detected"

        # Build comprehensive one-line resume sentence
        one_sentence = self._build_resume_line(
            langs, frameworks, skills, oop_analysis, duration
        )

        # Build detailed summary from OOP narrative
        narrative = oop_analysis.get("narrative", {})
        detailed_parts = []
        if summary:
            detailed_parts.append(summary)
        if narrative.get("oop"):
            detailed_parts.append(narrative["oop"])
        if narrative.get("data_structures"):
            detailed_parts.append(narrative["data_structures"])
        detailed_summary = " ".join(detailed_parts) if detailed_parts else "No detailed analysis available."

        # Build key responsibilities from analysis metrics
        responsibilities = []
        score_data = oop_analysis.get("score", {})
        classes_data = oop_analysis.get("classes", {})
        complexity = oop_analysis.get("complexity", {})

        if classes_data.get("count", 0) > 0:
            responsibilities.append(
                f"Designed and implemented {classes_data['count']} class(es) "
                f"with an average of {classes_data.get('avg_methods_per_class', 0)} methods per class"
            )
        if classes_data.get("with_inheritance", 0) > 0:
            responsibilities.append(
                f"Applied inheritance patterns in {classes_data['with_inheritance']} class(es) "
                "for code reuse and extensibility"
            )
        if complexity.get("total_functions", 0) > 0:
            responsibilities.append(
                f"Developed {complexity['total_functions']} functions with "
                f"max loop depth of {complexity.get('max_loop_depth', 0)}"
            )
        if oop_analysis.get("encapsulation", {}).get("classes_with_private_attrs", 0) > 0:
            responsibilities.append("Implemented encapsulation using private attributes for data protection")
        if oop_analysis.get("polymorphism", {}).get("classes_overriding_base_methods", 0) > 0:
            responsibilities.append("Utilized polymorphism through method overriding")

        if not responsibilities:
            responsibilities.append("Developed functional software solution")

        # Build OOP principles detected
        oop_principles: Dict[str, OOPPrinciple] = {}

        # Abstraction (based on class count and methods)
        class_count = classes_data.get("count", 0)
        oop_principles["abstraction"] = OOPPrinciple(
            present=class_count > 0,
            description=f"Project uses {class_count} class(es) to abstract functionality" if class_count > 0 else "",
            code_snippets=[]
        )

        # Encapsulation
        encap = oop_analysis.get("encapsulation", {})
        private_count = encap.get("classes_with_private_attrs", 0)
        oop_principles["encapsulation"] = OOPPrinciple(
            present=private_count > 0,
            description=f"{private_count} class(es) use private attributes for data hiding" if private_count > 0 else "",
            code_snippets=[]
        )

        # Inheritance
        inheritance_count = classes_data.get("with_inheritance", 0)
        oop_principles["inheritance"] = OOPPrinciple(
            present=inheritance_count > 0,
            description=f"{inheritance_count} class(es) extend base classes" if inheritance_count > 0 else "",
            code_snippets=[]
        )

        # Polymorphism
        poly = oop_analysis.get("polymorphism", {})
        override_count = poly.get("classes_overriding_base_methods", 0)
        override_methods = poly.get("override_method_count", 0)
        oop_principles["polymorphism"] = OOPPrinciple(
            present=override_count > 0,
            description=f"{override_count} class(es) override {override_methods} method(s) from base classes" if override_count > 0 else "",
            code_snippets=[]
        )

        # Build impact statement based on OOP score
        oop_score = score_data.get("oop_score", 0)
        rating = score_data.get("rating", "low")
        if oop_score >= 0.6:
            impact = (
                "Demonstrates strong object-oriented design with effective use of "
                "inheritance, encapsulation, and polymorphism for maintainable code."
            )
        elif oop_score >= 0.3:
            impact = (
                "Shows moderate application of OOP principles with room for "
                "deeper abstraction and design pattern usage."
            )
        else:
            impact = (
                "Functional implementation that achieves project goals with "
                "opportunities to enhance object-oriented structure."
            )

        # Combine skills
        all_skills = list(skills) if skills else list(langs)
        if rating == "high":
            all_skills.extend(["Object-Oriented Design", "Software Architecture"])
        elif rating == "medium":
            all_skills.append("Object-Oriented Programming")

        return ResumeItem(
            project_title=self.project_name,
            one_sentence_summary=one_sentence,
            detailed_summary=detailed_summary,
            key_responsibilities=responsibilities,
            key_skills_used=all_skills,
            tech_stack=tech_stack,
            impact=impact,
            oop_principles_detected=oop_principles
        )





